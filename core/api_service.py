import os
import logging
import time
import threading
from google import genai
from google.genai import types
from dotenv import load_dotenv

load_dotenv()

class APIService:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            logging.error("âŒ API Key missing!")
            return

        self.client = genai.Client(
            api_key=self.api_key,
            http_options={'api_version': 'v1beta'}
        )

        # âš¡ï¸ GÃœNCEL HIZ MOTORU: Gemini 2.5 Flash-Lite
        # Ultra dÃ¼ÅŸÃ¼k gecikme (latency) ve yÃ¼ksek iÅŸlem hacmi iÃ§in optimize edilmiÅŸ
        # en kararlÄ± ve hÄ±zlÄ± sÃ¼rÃ¼mdÃ¼r.
        self.model_name = "gemini-2.5-flash-lite" 
        
        # âš¡ï¸ OPTÄ°MÄ°ZASYON: Token Limiti & Sade Prompt
        # 2.5 Flash-Lite'Ä±n varsayÄ±lan limiti Ã§ok yÃ¼ksektir (65k+), ancak
        # biz anlÄ±k hÄ±z iÃ§in 2048 token (yaklaÅŸÄ±k 1500 kelime) ile sÄ±nÄ±rlandÄ±rÄ±yoruz.
        self.stream_config = types.GenerateContentConfig(
            temperature=0.3,
            max_output_tokens=2048,
            system_instruction="Translate to Academic Turkish (if input not TR) or Academic English (if TR). No explanations."
        )

        # ğŸ›¡ï¸ Ã‡Ä°FTE KORUMA (Latency Ã–nleyici)
        # Warmup: Ä°lk aÃ§Ä±lÄ±ÅŸtaki SSL el sÄ±kÄ±ÅŸmasÄ±nÄ± yapar.
        # Heartbeat: BaÄŸlantÄ±yÄ± sÃ¼rekli canlÄ± tutar.
        self.warmup()
        self._start_heartbeat()

    def warmup(self):
        """
        WARMUP (IsÄ±nma)
        Uygulama ilk aÃ§Ä±ldÄ±ÄŸÄ±nda Google sunucularÄ±na "Selam" vererek
        SSL/TLS tÃ¼nelini kazar. Ä°lk iÅŸlemin yavaÅŸ olmasÄ±nÄ± engeller.
        """
        def _warmup_task():
            try:
                logging.info(f"ğŸ”¥ [Warmup] {self.model_name} motoru Ä±sÄ±tÄ±lÄ±yor...")
                self.client.models.generate_content(
                    model=self.model_name,
                    contents="Hi",
                    config=types.GenerateContentConfig(max_output_tokens=1)
                )
                logging.info("âœ… [Warmup] Motor Ä±sÄ±ndÄ± ve hazÄ±r!")
            except Exception as e:
                logging.warning(f"IsÄ±nma hatasÄ± (Ã–nemli deÄŸil): {e}")

        threading.Thread(target=_warmup_task, daemon=True).start()

    def _start_heartbeat(self):
        """
        HEARTBEAT (Kalp AtÄ±ÅŸÄ±)
        Siz Ã§alÄ±ÅŸmasanÄ±z bile 45 saniyede bir boÅŸ sinyal gÃ¶ndererek
        Google ile olan hattÄ±n 'soÄŸumasÄ±nÄ±' ve kapanmasÄ±nÄ± engeller.
        """
        def _beat():
            # Warmup ile Ã§akÄ±ÅŸmamasÄ± iÃ§in 5 saniye bekle
            time.sleep(5) 
            logging.info("ğŸ’“ [Heartbeat] Servisi devrede.")
            
            while True:
                # 45 saniyede bir (Google genelde 60sn'de hattÄ± keser, biz 45 ile gÃ¼venli oynuyoruz)
                time.sleep(45)
                try:
                    # BoÅŸ bir ping at (Token maliyeti yok gibidir)
                    self.client.models.generate_content(
                        model=self.model_name,
                        contents=".",
                        config=types.GenerateContentConfig(max_output_tokens=1)
                    )
                    # LoglarÄ± kirletmemek iÃ§in pass geÃ§iyoruz, arka planda sessizce Ã§alÄ±ÅŸÄ±r.
                except Exception:
                    pass 

        threading.Thread(target=_beat, daemon=True).start()

    # âœ¨ YENÄ° FONKSÄ°YON: Humanize
    def humanize_text_stream(self, source_text, current_text):
        if not source_text: return
        
        HUMANIZE_SYSTEM_PROMPT = """
You are an expert academic editor. Your task is to rewrite the given text to make it indistinguishable from human writing, specifically to bypass AI detection filters.

Goal: High Perplexity and High Burstiness.
1.  **Perplexity (Complexity):** Avoid predictable word choices. Use varied vocabulary and slightly more complex sentence structures where appropriate for academia.
2.  **Burstiness (Sentence Variation):** AI generates sentences of uniform length. You must vary sentence length significantly. Mix short, punchy sentences with longer, complex compound sentences.

Strict Rules:
-   Preserve the original academic meaning 100%.
-   Do NOT be too formal/robotic. Use natural transitions (e.g., "Furthermore," "On the other hand," "Crucially").
-   If the text is in Turkish, write like a native Turkish academic (using proper terminology).
-   If in English, write like a native English scholar.
-   Output ONLY the rewritten text.
"""
        
        humanize_config = types.GenerateContentConfig(
            temperature=0.7, 
            max_output_tokens=2048,
            system_instruction=HUMANIZE_SYSTEM_PROMPT
        )

        user_prompt = f"Source Reference Text:\n{source_text}\n\nCurrent Text:\n{current_text}"
        
        # DEBUG LOG
        logging.critical("\n--- HUMANIZE PROMPT ---")
        logging.critical(f"Source Len: {len(source_text)}")
        logging.critical("-----------------------")

        try:
            response = self.client.models.generate_content_stream(
                model=self.model_name,
                contents=user_prompt,
                config=humanize_config
            )
            for chunk in response:
                if chunk.text: 
                    logging.critical(f"DEBUG CHUNK: {chunk.text[:20]}...") # Gelen veriyi gÃ¶r
                    yield chunk.text
        except Exception as e:
            logging.error(f"âŒ Humanize Error: {e}")
            yield f" [Error: {str(e)}]"

    def translate_text_stream(self, text):
        if not text: return
        try:
            response = self.client.models.generate_content_stream(
                model=self.model_name,
                contents=text,
                config=self.stream_config
            )
            for chunk in response:
                if chunk.text:
                    yield chunk.text
        except Exception as e:
            logging.error(f"âŒ API Stream Error: {e}")
            yield f" [Hata: {str(e)}]"
