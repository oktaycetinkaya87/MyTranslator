import os
import logging
import time
import threading
from google import genai
from google.genai import types
from dotenv import load_dotenv

load_dotenv()

class APIService:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            logging.error("‚ùå API Key missing!")
            return

        self.client = genai.Client(
            api_key=self.api_key,
            http_options={'api_version': 'v1beta'}
        )

        # ‚ö°Ô∏è G√úNCEL HIZ MOTORU: Gemini 2.5 Flash-Lite
        # Ultra d√º≈ü√ºk gecikme (latency) ve y√ºksek i≈ülem hacmi i√ßin optimize edilmi≈ü
        # en kararlƒ± ve hƒ±zlƒ± s√ºr√ºmd√ºr.
        self.model_name = "gemini-2.5-flash-lite" 
        
        # ‚ö°Ô∏è OPTƒ∞Mƒ∞ZASYON: Token Limiti & Sade Prompt
        # 2.5 Flash-Lite'ƒ±n varsayƒ±lan limiti √ßok y√ºksektir (65k+), ancak
        # biz anlƒ±k hƒ±z i√ßin 2048 token (yakla≈üƒ±k 1500 kelime) ile sƒ±nƒ±rlandƒ±rƒ±yoruz.
        self.stream_config = types.GenerateContentConfig(
            temperature=0.3,
            max_output_tokens=2048,
            system_instruction="Translate to Academic Turkish (if input not TR) or Academic English (if TR). No explanations."
        )

        # üõ°Ô∏è √áƒ∞FTE KORUMA (Latency √ñnleyici)
        # Warmup: ƒ∞lk a√ßƒ±lƒ±≈ütaki SSL el sƒ±kƒ±≈ümasƒ±nƒ± yapar.
        # Heartbeat: Baƒülantƒ±yƒ± s√ºrekli canlƒ± tutar.
        self.warmup()
        self._start_heartbeat()

    def warmup(self):
        """
        WARMUP (Isƒ±nma)
        Uygulama ilk a√ßƒ±ldƒ±ƒüƒ±nda Google sunucularƒ±na "Selam" vererek
        SSL/TLS t√ºnelini kazar. ƒ∞lk i≈ülemin yava≈ü olmasƒ±nƒ± engeller.
        """
        def _warmup_task():
            try:
                logging.info(f"üî• [Warmup] {self.model_name} motoru ƒ±sƒ±tƒ±lƒ±yor...")
                self.client.models.generate_content(
                    model=self.model_name,
                    contents="Hi",
                    config=types.GenerateContentConfig(max_output_tokens=1)
                )
                logging.info("‚úÖ [Warmup] Motor ƒ±sƒ±ndƒ± ve hazƒ±r!")
            except Exception as e:
                logging.warning(f"Isƒ±nma hatasƒ± (√ñnemli deƒüil): {e}")

        threading.Thread(target=_warmup_task, daemon=True).start()

    def _start_heartbeat(self):
        """
        HEARTBEAT (Kalp Atƒ±≈üƒ±)
        Siz √ßalƒ±≈ümasanƒ±z bile 45 saniyede bir bo≈ü sinyal g√∂ndererek
        Google ile olan hattƒ±n 'soƒüumasƒ±nƒ±' ve kapanmasƒ±nƒ± engeller.
        """
        def _beat():
            # Warmup ile √ßakƒ±≈ümamasƒ± i√ßin 5 saniye bekle
            time.sleep(5) 
            logging.info("üíì [Heartbeat] Servisi devrede.")
            
            while True:
                # 45 saniyede bir (Google genelde 60sn'de hattƒ± keser, biz 45 ile g√ºvenli oynuyoruz)
                time.sleep(45)
                try:
                    # Bo≈ü bir ping at (Token maliyeti yok gibidir)
                    self.client.models.generate_content(
                        model=self.model_name,
                        contents=".",
                        config=types.GenerateContentConfig(max_output_tokens=1)
                    )
                    # Loglarƒ± kirletmemek i√ßin pass ge√ßiyoruz, arka planda sessizce √ßalƒ±≈üƒ±r.
                except Exception:
                    pass 

        threading.Thread(target=_beat, daemon=True).start()

    # ‚ú® YENƒ∞ FONKSƒ∞YON: Humanize
    def humanize_text_stream(self, source_text, current_text):
        if not source_text: return
        
        HUMANIZE_SYSTEM_PROMPT = """
You are an expert academic editor. Your task is to rewrite the 'Current Text' to make it indistinguishable from human writing, specifically to bypass AI detection filters.

Goal: High Perplexity and High Burstiness.
1.  **Perplexity (Complexity):** Avoid predictable word choices. Use varied vocabulary and slightly more complex sentence structures where appropriate for academia.
2.  **Burstiness (Sentence Variation):** AI generates sentences of uniform length. You must vary sentence length significantly. Mix short, punchy sentences with longer, complex compound sentences.

Strict Rules:
-   **CRITICAL:** OUTPUT MUST BE IN THE SAME LANGUAGE AS THE 'Current Text'.
-   **NEVER** translate the text back to the 'Source Reference Text' language.
-   Preserve the original academic meaning 100%.
-   Do NOT be too formal/robotic. Use natural transitions (e.g., "Furthermore," "On the other hand," "Crucially").
-   If 'Current Text' is Turkish -> Output Turkish.
-   If 'Current Text' is English -> Output English.
-   Output ONLY the rewritten text.
"""
        
        humanize_config = types.GenerateContentConfig(
            temperature=0.7, 
            max_output_tokens=2048,
            system_instruction=HUMANIZE_SYSTEM_PROMPT
        )

        user_prompt = f"Source Reference Text:\n{source_text}\n\nCurrent Text:\n{current_text}"
        
        # DEBUG LOG
        logging.critical("\n--- HUMANIZE PROMPT ---")
        logging.critical(f"Source Len: {len(source_text)}")
        logging.critical("-----------------------")

        try:
            response = self.client.models.generate_content_stream(
                model=self.model_name,
                contents=user_prompt,
                config=humanize_config
            )
            for chunk in response:
                if chunk.text: 
                    logging.critical(f"DEBUG CHUNK: {chunk.text[:20]}...") # Gelen veriyi g√∂r
                    yield chunk.text
        except Exception as e:
            logging.error(f"‚ùå Humanize Error: {e}")
            yield f" [Error: {str(e)}]"

    def translate_text_stream(self, text):
        if not text: return
        try:
            response = self.client.models.generate_content_stream(
                model=self.model_name,
                contents=text,
                config=self.stream_config
            )
            for chunk in response:
                if chunk.text:
                    yield chunk.text
        except Exception as e:
            logging.error(f"‚ùå API Stream Error: {e}")
            yield f" [Hata: {str(e)}]"
